{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9be04a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv \n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, trim_messages\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a712f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "def get_message_history(session_id: str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e26a3fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model=\"Gemma2-9b-It\", groq_api_key=os.getenv('GROQ_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af2395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's fantastic!  It's great to see a MERN stack developer expanding their skillset into the world of AI/ML. Your background in web development will be a real asset as you learn these new technologies. \\n\\nHere are some thoughts to get you started:\\n\\n**Bridging the Gap:**\\n\\n* **Data is Key:**  AI/ML thrives on data.  You'll likely need to learn about data cleaning, preprocessing, and manipulation, which can complement your existing skills in handling data on the web.\\n* **Backend Power:** Your MERN stack experience with Node.js and databases will be valuable for building the backend infrastructure to support AI/ML models.\\n\\n**Areas to Explore:**\\n\\n* **Computer Vision for Web Apps:** Imagine adding image recognition to your projects.  You could build features like:\\n    * Product tagging and search\\n    * Content moderation\\n    * Image-based filters\\n* **Natural Language Processing (NLP):**  Power up your web applications with:\\n    * Chatbots and conversational interfaces\\n    * Text summarization and analysis\\n    * Sentiment analysis for understanding user feedback\\n* **Predictive Analytics:**\\n    * Use user data to personalize recommendations\\n    * Forecast trends and user behavior\\n\\n**Learning Resources:**\\n\\n* **Python:**  While you might be comfortable with JavaScript, Python is the dominant language in AI/ML. There are many great resources to learn Python, even if you're not a programmer by background.\\n* **Machine Learning Libraries:** TensorFlow and PyTorch are powerful frameworks for building and training AI models.\\n\\n**Tips for Success:**\\n\\n* **Start Small:** Begin with simple projects to grasp the fundamentals.\\n* **Find a Community:**  Connect with other learners and experts online or in person.\\n* **Don't Be Afraid to Experiment:** AI/ML is all about trying things out and seeing what works.\\n\\nLet me know if you have any more specific questions as you embark on this exciting journey!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 414, 'prompt_tokens': 623, 'total_tokens': 1037, 'completion_time': 0.752727273, 'prompt_time': 0.012317032, 'queue_time': 0.250195888, 'total_time': 0.765044305}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--52652a8d-36e2-4427-9716-7cafd09883c5-0', usage_metadata={'input_tokens': 623, 'output_tokens': 414, 'total_tokens': 1037})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automtatically injects past messages and persists new ones based on session_id from config\n",
    "with_message_history = RunnableWithMessageHistory(model, get_message_history)\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, I'm a MERN stack developer learning AI/ML.\")],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f97aa53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§®‡§Æ‡§∏‡•ç‡§§‡•á!  \\n\\n‡§Ø‡§π ‡§ú‡§æ‡§®‡§ï‡§∞ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§≤‡§ó‡§æ ‡§ï‡§ø ‡§Ü‡§™ ‡§è‡§ï Java ‡§°‡•á‡§µ‡§≤‡§™‡§∞ ‡§π‡•à‡§Ç!  \\n\\n‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§Ø‡§æ ‡§Æ‡§¶‡§¶ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?  ‡§Æ‡•à‡§Ç ‡§®‡§ø‡§Æ‡•ç‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å:\\n\\n* **Java ‡§Ö‡§µ‡§ß‡§æ‡§∞‡§£‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§∏‡§Æ‡§ù‡§æ‡§®‡§æ:**  ‡§™‡•â‡§≤‡•Ä‡§Æ‡•â‡§∞‡•ç‡§´‡§ø‡§ú‡•ç‡§Æ ‡§Ø‡§æ ‡§ú‡§®‡§∞‡§ø‡§ï‡•ç‡§∏ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§∞‡§ø‡§´‡•ç‡§∞‡•á‡§∂‡§∞ ‡§ö‡§æ‡§π‡§ø‡§è?\\n* **‡§ï‡•ã‡§° ‡§°‡•Ä‡§¨‡§ó‡§ø‡§Ç‡§ó:**  ‡§ï‡•ã‡§à ‡§Æ‡•Å‡§∂‡•ç‡§ï‡§ø‡§≤ ‡§¨‡§ó‡§º ‡§Æ‡•á‡§Ç ‡§´‡§Ç‡§∏‡•á ‡§π‡•à‡§Ç? ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•ã ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡§æ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§ñ‡•ã‡§ú‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å‡•§\\n* **‡§ï‡•ã‡§° ‡§∏‡•ç‡§®‡§ø‡§™‡•á‡§ü ‡§ú‡§®‡§∞‡•á‡§ü ‡§ï‡§∞‡§®‡§æ:**  ‡§ï‡§ø‡§∏‡•Ä ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•ç‡§µ‡§∞‡§ø‡§§ ‡§ï‡•ã‡§° ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§π‡•à?\\n* **‡§¨‡•á‡§∏‡•ç‡§ü ‡§™‡•ç‡§∞‡•à‡§ï‡•ç‡§ü‡§ø‡§∏ ‡§™‡§∞ ‡§ö‡§∞‡•ç‡§ö‡§æ ‡§ï‡§∞‡§®‡§æ:**  ‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï Java ‡§°‡•á‡§µ‡§≤‡§™‡§Æ‡•á‡§Ç‡§ü ‡§§‡§ï‡§®‡•Ä‡§ï‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?\\n* **‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§ñ‡•ã‡§ú‡§®‡•á:**  ‡§ü‡•ç‡§Ø‡•Ç‡§ü‡•ã‡§∞‡§ø‡§Ø‡§≤, ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º ‡§Ø‡§æ ‡§≤‡§æ‡§á‡§¨‡•ç‡§∞‡•á‡§∞‡•Ä ‡§ï‡•Ä ‡§§‡§≤‡§æ‡§∂ ‡§π‡•à?\\n\\n\\n ‡§¨‡§∏ ‡§Æ‡•Å‡§ù‡•á ‡§¨‡§§‡§æ‡§è‡§Ç ‡§ï‡§ø ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§∏‡•ã‡§ö ‡§∞‡§π‡•á ‡§π‡•à‡§Ç! üòä \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 248, 'prompt_tokens': 196, 'total_tokens': 444, 'completion_time': 0.450909091, 'prompt_time': 0.004545124, 'queue_time': 0.252167555, 'total_time': 0.455454215}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--6e9b7ce0-da23-4572-86b5-f5f379b86bd5-0', usage_metadata={'input_tokens': 196, 'output_tokens': 248, 'total_tokens': 444})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer all questions in {language} to the best of your abilities.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "chain = prompt | model\n",
    "with_message_history = RunnableWithMessageHistory(chain, get_message_history, input_messages_key=\"messages\")\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"chat2\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(\"Hi, I'm a Java developer\")], \n",
    "        \"language\": \"Hindi\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e53bb5c",
   "metadata": {},
   "source": [
    "### Managing conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df73e6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You're a helpful assistant who can answer all questions\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is the capital of India?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='New Delhi', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You're a helpful assistant who can answer all questions\"),\n",
    "    HumanMessage(content=\"Hi, I'm Bob\"),\n",
    "    AIMessage(content=\"Hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "    HumanMessage(content=\"What is the capital of India?\"),\n",
    "    AIMessage(content=\"New Delhi\"),\n",
    "]\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e974049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"2 + 3 = 5  \\n\\nIt's like adding two friends to three friends. You get a group of five friends! ü•≥\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 80, 'total_tokens': 112, 'completion_time': 0.058181818, 'prompt_time': 0.00250301, 'queue_time': 0.25179336, 'total_time': 0.060684828}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a5b5a119-77e4-405b-8f25-952cb3538429-0', usage_metadata={'input_tokens': 80, 'output_tokens': 32, 'total_tokens': 112})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Input comes in (likely {\"messages\": [chat_history], \"user\": ...}).\n",
    "RunnablePassthrough.assign ‚Üí modifies \"messages\" by trimming old/long parts.\n",
    "Passes modified data to prompt, which structures it into a text prompt.\n",
    "That structured prompt goes into the model.\n",
    "Model generates the answer.\n",
    "\"\"\"\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer) | \n",
    "    prompt | \n",
    "    model\n",
    ")\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain, get_message_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "    \"messages\": messages + [HumanMessage(\"What is the capital of Ukraine?\")],\n",
    "    \"language\": \"English\"\n",
    "    }, \n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e9cae13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As a helpful and harmless AI assistant, I have no memory of past conversations. Every interaction we have is fresh and new!\\n\\nIf you'd like to ask me a math problem now, I'm happy to help. üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 68, 'total_tokens': 120, 'completion_time': 0.094545455, 'prompt_time': 0.002278689, 'queue_time': 0.250143582, 'total_time': 0.096824144}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--8b9271c8-319d-4487-aa5a-49361a8ef394-0', usage_metadata={'input_tokens': 68, 'output_tokens': 52, 'total_tokens': 120})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "    \"messages\": messages + [HumanMessage(\"What was the last Math problem which I asked?\")],\n",
    "    \"language\": \"English\"\n",
    "    }, \n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
