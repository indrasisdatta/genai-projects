{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12491128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv \n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser \n",
    "from pydantic import BaseModel, Field \n",
    "from typing import Literal \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableParallel, RunnableBranch, RunnableLambda\n",
    "import os \n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "os.environ[\"HF_HOME\"] = os.getenv(\"HF_HOME\")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c004bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    task=\"text-generation\"\n",
    ")\n",
    "# llm2 = HuggingFaceEndpoint(\n",
    "#     repo_id=\"openai/gpt-oss-20b\",\n",
    "#     task=\"text-generation\"\n",
    "# )\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "# model2 = ChatHuggingFace(llm=llm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Classify the sentiment of the following feedback as positive or negative: \\n {feedback}\",\n",
    "    input_variables=[\"feedback\"]\n",
    ")\n",
    "classifier_chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a74239c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of this feedback is negative.\n"
     ]
    }
   ],
   "source": [
    "print(classifier_chain.invoke({\"feedback\": \"this is a terrible smartphone\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f4d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedback(BaseModel):\n",
    "    # Literal['positive', 'negative'] \n",
    "    sentiment: Literal['positive', 'negative'] = Field(description=\"Give the sentiment of the feedback as either 'positive' or 'negative'\")\n",
    "\n",
    "parser2 = PydanticOutputParser(pydantic_object=Feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad066fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment='negative'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "template = \"\"\"Classify the sentiment of the following feedback as positive or negative.\n",
    "\n",
    "Feedback: {feedback}\n",
    "\n",
    "Return only valid JSON in this exact format:\n",
    "{format_instruction}\n",
    "\"\"\"\n",
    "\n",
    "# print(parser2.get_format_instructions())\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"feedback\"],\n",
    "    partial_variables={\n",
    "        \"format_instruction\": parser2.get_format_instructions()\n",
    "    }\n",
    ")\n",
    "classifier_chain = prompt | model | parser2\n",
    "print(classifier_chain.invoke({\"feedback\": \"I dislike the features of this smartphone\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16397e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an example of a constructive response to negative feedback:\n",
      "\n",
      "\"Thank you for taking the time to share your thoughts on my performance. I appreciate your honesty and value your feedback. I can see that there are areas where I can improve, and I'm committed to working on those specific points. Can you please provide more details on what you think I could do differently in the future? I'm eager to learn and grow from this experience.\"\n",
      "\n",
      "This response acknowledges the negative feedback, expresses gratitude for the feedback, and shows a willingness to learn and improve. By asking for specific details, you're also showing that you're interested in understanding the feedback and using it to make positive changes.\n",
      "\n",
      "Alternatively, you could also respond with:\n",
      "\n",
      "\"I appreciate your feedback and I'm sorry to hear that I didn't meet your expectations. I'll take your comments into consideration and work on making improvements. If there's anything specific you'd like me to focus on, please let me know. I'm committed to delivering high-quality results and I appreciate your help in helping me get there.\"\n",
      "\n",
      "This response is also constructive and shows that you're taking the feedback seriously, while also expressing appreciation for the person's input.\n"
     ]
    }
   ],
   "source": [
    "prompt_pos = PromptTemplate(\n",
    "    template=\"Write an appropriate feedback to this positive feedback \\n {feedback}\",\n",
    "    input_variables={\"feedback\"}\n",
    ")\n",
    "prompt_neg = PromptTemplate(\n",
    "    template=\"Write an appropriate feedback to this negative feedback \\n {feedback}\",\n",
    "    input_variables={\"feedback\"}\n",
    ")\n",
    "\n",
    "branch_chain = RunnableBranch(\n",
    "    (lambda x:x.sentiment == 'positive', prompt_pos | model | parser),\n",
    "    (lambda x:x.sentiment == 'negative', prompt_neg | model | parser),\n",
    "    RunnableLambda(lambda x: \"could not find sentiment\")\n",
    ")\n",
    "\n",
    "chain = classifier_chain | branch_chain\n",
    "\n",
    "print(chain.invoke({'feedback': 'This is a beautiful phone'}))\n",
    "\n",
    "\n",
    "# branch_chain = RunnableBranch(\n",
    "#     (lambda x: x[\"sentiment\"] == \"positive\", prompt_pos | model | parser),\n",
    "#     (lambda x: x[\"sentiment\"] == \"negative\", prompt_neg | model | parser),\n",
    "#     RunnableLambda(lambda x: \"Could not find sentiment\")\n",
    "# )\n",
    "\n",
    "# # chain = classifier_chain | to_dict | branch_chain \n",
    "\n",
    "# to_dict = RunnableLambda(lambda x: x.dict())\n",
    "\n",
    "# def enrich_input(x, sentiment_result):\n",
    "#     return {\n",
    "#         \"feedback\": x[\"feedback\"],\n",
    "#         \"sentiment\": sentiment_result.sentiment\n",
    "#     }\n",
    "\n",
    "# merge_chain = RunnableLambda(\n",
    "#     lambda x: enrich_input(x, x[\"classifier_output\"])\n",
    "# )\n",
    "\n",
    "# # chain = {\n",
    "# #     \"feedback\": lambda x: x[\"feedback\"],\n",
    "# #     \"classifier_output\": classifier_chain\n",
    "# # } | merge_chain | branch_chain \n",
    "\n",
    "# chain = classifier_chain | merge_chain | branch_chain\n",
    "\n",
    "# print(chain.invoke({\"feedback\": \"This is a bad phone\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
